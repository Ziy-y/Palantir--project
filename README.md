# Semantic visualization of the Biotech patent database

Overview

This project is integrated with [pavilions-ai] and implements a semantic search system designed to query technical documents (such as service manuals, patents, and biology research papers). The platform allows users to ask natural-language questions and retrieve the most relevant chunks of information from unstructured documents. It is especially useful for technicians, researchers, and analysts working with large volumes of technical PDFs, enabling fast retrieval of context-aware answers.

Features

- Semantic Querying: Search across documents using natural language instead of keyword-only search.
- Chunk-based Retrieval: Documents are split into meaningful text chunks for precise matches.
- RAG Integration: Uses Retrieval-Augmented Generation (RAG) workflows to provide contextual LLM answers.
- Entity Extraction: Automatically extracts structured metadata (entities) from documents.
- Visualization: Interactive graph interface for exploring linked documents and concepts.
- Embeddings Pipeline: Generates vector embeddings for each text chunk, enabling similarity search.

Example Use Cases

1. Manufacturing Manuals: A technician can ask “How do I reset the dispensing system?” and retrieve the relevant manual section.
2. Biology Research: A researcher can query “What is BBB delivery in biology?” and get an explanation of blood-brain barrier delivery methods (nanoparticles, receptor-mediated transport, ultrasound, etc.).
3. Patents: Analysts can semantically search patents for mentions of specific technologies or claims.

System Workflow

The pipeline follows these main steps (see pipeline diagram screenshot):
1. PDF Ingestion
- Input: Technical manuals, patents, or scientific papers.
2. Text Extraction
- Extracts unstructured text from PDFs.
3. Entity Extraction (LLM)
- Uses an LLM to identify and tag relevant entities (e.g., drugs, proteins, systems).
4. Preprocessing & Chunking
- Splits documents into smaller, semantically meaningful chunks.
5. Embedding Generation
- Each chunk is converted into vector embeddings.
6. Vector Database Storage
- Stores embeddings for fast similarity-based retrieval.
7. Semantic Search & RAG
- Queries are embedded and matched against stored chunks.
- Retrieved context is passed to an LLM to generate an answer
<img width="1724" height="368" alt="ad0d58522c425ef47840afe306e0caff" src="https://github.com/user-attachments/assets/5c9282e7-2789-489e-ad3e-a83d66fc0744" />

User Interface

- Search Box: Type natural-language questions.
- Results Panel: Shows most relevant chunks retrieved from documents.
- LLM Response Panel: Displays contextualized answer generated by the LLM.
- Graph Explorer: Interactive view of related documents and entities.
<img width="1398" height="910" alt="947b6967a73fd000739b4a98815cdc42" src="https://github.com/user-attachments/assets/b840a0d2-8f8e-4833-a458-35ad6baae5fc" />
<img width="1886" height="1538" alt="07eccea2a86de237a4b73cd5d7738296" src="https://github.com/user-attachments/assets/8d04e1fb-5d70-4e2a-a0be-251828ce1e6a" />

Tech Stack

- Document Processing: PDF text extraction
- LLM: For entity extraction and RAG responses
- Embeddings: Vector representations for semantic similarity
- Visualization: Interactive graph and chunk inspection tools
- Pipeline Orchestration: End-to-end processing with checkpoints

Future Improvements

- Add multi-document summarization for long queries.
- Expand to support audio/video transcripts.
- Optimize chunking strategy for larger documents.
- Incorporate domain-specific embeddings for higher accuracy.
- Replace the input documents of the pipeline with your own  datasets
- Adjust the entity selection box to customize  your own entities

How to Use

1. Upload documents (PDFs).
2. Enter a natural-language question in the search box.
3. Review results in:
   - Relevant Chunks (direct document matches)
   - LLM Response (context-aware explanation)
4. Explore document relationships in the graph view.

Contact

If you have any questions about this project, feel free to contact Peixin <peixin@pavilions.ai> and Ziyue <ziyueyin7@gmail.com>
   
## Upload Package to Your Enrollment

The first step is uploading your package to the Foundry Marketplace:

1. Download the project's `.zip` file from this repository
2. Access your enrollment's marketplace at:
   ```
   {enrollment-url}/workspace/marketplace
   ```
3. In the marketplace interface, initiate the upload process:
   - Select or create a store in your preferred project folder
   - Click the "Upload to Store" button
   - Select your downloaded `.zip` file

![Marketplace Interface](./../_static/upload_product_banner.png)

## Install the Package

After upload, you'll need to install the package in your environment. For detailed instructions, see the [official Palantir documentation](https://www.palantir.com/docs/foundry/marketplace/install-product).

The installation process has four main stages:

1. **General Setup**
   - Configure package name
   - Select installation location

2. **Input Configuration**
   - Configure any required inputs. If no inputs are needed, proceed to next step
   - Check project documentation for specific input requirements

3. **Content Review**
   - Review resources to be installed such as Developer Console, the Ontology, and Functions

4. **Validation**
   - System checks for any configuration errors
   - Resolve any flagged issues
   - Initiate installation


## SDK Configuration (Optional)

Some packages include applications built with the Ontology SDK. These require additional setup:

1. Locate the SDK application code in the `app/` directory of the project repository

2. The following details will need to added to the source code for the application.  
   - Navigate to Developer Console: `{enrollment-url}/workspace/developer-console`
   - Find the installed application
   - Copy the following details:
     - CLIENT ID
     - Enrollment URL `{enrollment-url}.palantirfoundry.com`

3. Configure your development environment:
   - Add to `env.development` file under `app/`
   - (optional) Configure CORS in your control panel to allow `http://localhost:8080`

### Local Development
<p align="center">
<img width="650" src=./../_static/start%20developing.png>
</p>

**To run the application locally:**
1. Access the Developer Console's "Start Developing" section
2. Follow the "Add Ontology SDK" setup process)
3. In the `/app` directory, start the development server:
   ```sh
   npm run dev
   ```
   This will launch your application at `http://localhost:8080`
